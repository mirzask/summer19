{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer and TfidfVectorizer\n",
    "\n",
    "This example also plays around with the movie reviews dataset from NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer,  TfidfTransformer\n",
    "\n",
    "from nltk.corpus import stopwords, movie_reviews\n",
    "\n",
    "labels = [re.match(r\"\\w{3}\", l)[0] for l in movie_reviews.fileids()]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {'text':movie_reviews.raw(fileids=[l]),'label': re.match(r\"\\w{3}\", l)[0]} for l in movie_reviews.fileids()\n",
    ")\n",
    "\n",
    "# Create a list of punctuation\n",
    "punctuations = list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[re.match(r\"\\w{3}\", l)[0] for l in movie_reviews.fileids()[1:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>plot : two teen couples go to a church party ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>the happy bastard's quick movie review \\ndamn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>it is movies like these that make a jaded movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>\" quest for camelot \" is warner bros . ' firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>synopsis : a mentally unstable man undergoing ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   neg  plot : two teen couples go to a church party ,...\n",
       "1   neg  the happy bastard's quick movie review \\ndamn ...\n",
       "2   neg  it is movies like these that make a jaded movi...\n",
       "3   neg   \" quest for camelot \" is warner bros . ' firs...\n",
       "4   neg  synopsis : a mentally unstable man undergoing ..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuations[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation from the text\n",
    "df['text'] = df.text.apply(lambda x: \" \".join(x for x in x.split() if x not in punctuations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>plot two teen couples go to a church party dri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>the happy bastard's quick movie review damn th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>it is movies like these that make a jaded movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>quest for camelot is warner bros first feature...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>synopsis a mentally unstable man undergoing ps...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   neg  plot two teen couples go to a church party dri...\n",
       "1   neg  the happy bastard's quick movie review damn th...\n",
       "2   neg  it is movies like these that make a jaded movi...\n",
       "3   neg  quest for camelot is warner bros first feature...\n",
       "4   neg  synopsis a mentally unstable man undergoing ps..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words from text\n",
    "# df['text'] = df.text.apply(lambda x: \" \".join(x for x in x.split() if x not in stops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer\n",
    "\n",
    "Creates a sparse data matrix\n",
    "\n",
    "- `lowercase = TRUE` is default\n",
    "- exclude stop words using `stop_words = 'english'`\n",
    "- tokenize based on RegEx pattern using `token_pattern = r\"\\b\\w+\\b\"`\n",
    "- remove infrequent words with `min_df=2`, i.e. excludes word if in < 2 documents\n",
    "- keep a specified number of the most common words with `max_features=100`, i.e. keep only 100 most common words\n",
    "- specify a vocabulary/dictionay with `vocabulary = <dictionary>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hereby', 'go', 'although', 'thus', 'each', 'should', 'cant', 'would', 'thick', 'only', 'except', 'four', 'mostly', 'my', 'she', 'yourself', 'found', 'several', 'full', 'nowhere']\n"
     ]
    }
   ],
   "source": [
    "# Stop words in sklearn\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "print(list(ENGLISH_STOP_WORDS)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class balance:\n",
      " neg    1000\n",
      "pos    1000\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y = df.label\n",
    "\n",
    "print(\"class balance:\\n\", df.label.value_counts())\n",
    "\n",
    "text_train, text_test, y_train, y_test = train_test_split(df['text'], y,\n",
    "                                                    test_size = 0.33,\n",
    "                                                    stratify = y,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words = 'english')\n",
    "\n",
    "X_train = vect.fit_transform(text_train.values)\n",
    "X_test = vect.transform(text_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '007', '00s', '05', '10', '100', '1000', '100m', '101']\n",
      "['neophytes', 'nephew', 'nephews', 'nepotist', 'neptune', 'nerd', 'nerdies', 'nerds', 'nerdy', 'neri', 'nero', 'nerve', 'nerves', 'nerving', 'nervous', 'nervously', 'nervousness', 'nescafe', 'nesmith', 'ness']\n",
      "['00', 'asked', 'brilliant', 'compartmented', 'desperately', 'entrenched', 'fundamentalist', 'hisses', 'jew', 'mails', 'neophytes', 'pianist', 'recite', 'scrapped', 'sprucing', 'tiering', 'vieluf']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check on the vocabulary\n",
    "\n",
    "feature_names = vect.get_feature_names()\n",
    "print(feature_names[:10]), print(feature_names[20000:20020]), print(feature_names[::2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>007</th>\n",
       "      <th>00s</th>\n",
       "      <th>05</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>100m</th>\n",
       "      <th>101</th>\n",
       "      <th>...</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zsigmond</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zuehlke</th>\n",
       "      <th>zuko</th>\n",
       "      <th>zurg</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zwigoff</th>\n",
       "      <th>zycie</th>\n",
       "      <th>zzzzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33446 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  007  00s  05  10  100  1000  100m  101  ...  zorro  zsigmond  \\\n",
       "0   0    0    0    0   0   0    0     0     0    0  ...      0         0   \n",
       "1   0    0    0    0   0   0    0     0     0    0  ...      0         0   \n",
       "2   0    0    0    0   0   1    0     0     0    0  ...      0         0   \n",
       "3   0    0    0    0   0   0    0     0     0    0  ...      0         0   \n",
       "4   0    0    0    0   0   0    0     0     0    0  ...      0         0   \n",
       "\n",
       "   zucker  zuehlke  zuko  zurg  zwick  zwigoff  zycie  zzzzzzz  \n",
       "0       0        0     0     0      0        0      0        0  \n",
       "1       0        0     0     0      0        0      0        0  \n",
       "2       0        0     0     0      0        0      0        0  \n",
       "3       0        0     0     0      0        0      0        0  \n",
       "4       0        0     0     0      0        0      0        0  \n",
       "\n",
       "[5 rows x 33446 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df = pd.DataFrame(X_train.A, columns=vect.get_feature_names())\n",
    "\n",
    "count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asnasiddiqui/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8257575757575758"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification w/ Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "lr = LogisticRegressionCV().fit(X_train, y_train)\n",
    "\n",
    "lr.C_\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words = 'english', max_df = 0.7)\n",
    "\n",
    "X_tfidf = tfidf.fit_transform(text_train)\n",
    "#X_tfidf.toarray()\n",
    "\n",
    "# First five vectors of TFIDF training data\n",
    "X_tfidf.A[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['affords',\n",
       " 'affraid',\n",
       " 'affront',\n",
       " 'afi',\n",
       " 'aficionado',\n",
       " 'aficionados',\n",
       " 'afloat',\n",
       " 'afo',\n",
       " 'afoot',\n",
       " 'afore']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset of features from TF-IDF\n",
    "tfidf.get_feature_names()[1000:1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>007</th>\n",
       "      <th>00s</th>\n",
       "      <th>05</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>100m</th>\n",
       "      <th>101</th>\n",
       "      <th>...</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zsigmond</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zuehlke</th>\n",
       "      <th>zuko</th>\n",
       "      <th>zurg</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zwigoff</th>\n",
       "      <th>zycie</th>\n",
       "      <th>zzzzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33443 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  007  00s   05        10  100  1000  100m  101  ...  zorro  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0   0.0   0.0  0.0  ...    0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.000000  0.0   0.0   0.0  0.0  ...    0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.043446  0.0   0.0   0.0  0.0  ...    0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.000000  0.0   0.0   0.0  0.0  ...    0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.000000  0.0   0.0   0.0  0.0  ...    0.0   \n",
       "\n",
       "   zsigmond  zucker  zuehlke  zuko  zurg  zwick  zwigoff  zycie  zzzzzzz  \n",
       "0       0.0     0.0      0.0   0.0   0.0    0.0      0.0    0.0      0.0  \n",
       "1       0.0     0.0      0.0   0.0   0.0    0.0      0.0    0.0      0.0  \n",
       "2       0.0     0.0      0.0   0.0   0.0    0.0      0.0    0.0      0.0  \n",
       "3       0.0     0.0      0.0   0.0   0.0    0.0      0.0    0.0      0.0  \n",
       "4       0.0     0.0      0.0   0.0   0.0    0.0      0.0    0.0      0.0  \n",
       "\n",
       "[5 rows x 33443 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df = pd.DataFrame(X_tfidf.A, columns=tfidf.get_feature_names())\n",
    "\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "tfidf_pipe = make_pipeline(CountVectorizer(),\n",
    "                          TfidfTransformer()).fit_transform(text_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-grams\n",
    "\n",
    "BOW does not account for word order, i.e. unable to distinguihs between \"not dead\" and \"dead.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"This is how you get ants.\", \"It is not pleasant.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  9\n",
      "Vocabulary:\n",
      " ['ants', 'get', 'how', 'is', 'it', 'not', 'pleasant', 'this', 'you']\n"
     ]
    }
   ],
   "source": [
    "# Only 1-grams\n",
    "cv = CountVectorizer(ngram_range=(1, 1)).fit(corpus)\n",
    "print(\"Vocabulary size: \", len(cv.vocabulary_))\n",
    "print(\"Vocabulary:\\n\", cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  8\n",
      "Vocabulary:\n",
      " ['get ants', 'how you', 'is how', 'is not', 'it is', 'not pleasant', 'this is', 'you get']\n"
     ]
    }
   ],
   "source": [
    "# Only 2-grams\n",
    "cv = CountVectorizer(ngram_range=(2, 2)).fit(malory)\n",
    "print(\"Vocabulary size: \", len(cv.vocabulary_))\n",
    "print(\"Vocabulary:\\n\", cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  17\n",
      "Vocabulary:\n",
      " ['ants', 'get', 'get ants', 'how', 'how you', 'is', 'is how', 'is not', 'it', 'it is', 'not', 'not pleasant', 'pleasant', 'this', 'this is', 'you', 'you get']\n"
     ]
    }
   ],
   "source": [
    "# 1-grams and 2-grams\n",
    "cv = CountVectorizer(ngram_range=(1, 2)).fit(malory)\n",
    "print(\"Vocabulary size: \", len(cv.vocabulary_))\n",
    "print(\"Vocabulary:\\n\", cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2), min_df=4:  396750\n",
      "(1, 2), stopwords, min_df=4:  18074\n"
     ]
    }
   ],
   "source": [
    "# 1- and 2-grams; exclude stop words\n",
    "cv = CountVectorizer(ngram_range=(1, 2), min_df=1)\n",
    "cv.fit(text_train)\n",
    "print(\"(1, 2), min_df=4: \", len(cv.vocabulary_))\n",
    "cv = CountVectorizer(ngram_range=(1, 2), min_df=4,\n",
    "                     stop_words=\"english\")\n",
    "cv.fit(text_train)\n",
    "print(\"(1, 2), stopwords, min_df=4: \", len(cv.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing stopwords helps decrease our feature space considerably."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
