{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training/Updating models in spaCy\n",
    "\n",
    "> **Training**: requires a few thousand to a million examples\n",
    "\n",
    "> **Updating** an existing model: a few hundred to a few thousand examples\n",
    "\n",
    "> Can be *semi-automated* using `Matcher`\n",
    "\n",
    "1. Initialize the model weights randomly with `nlp.begin_training`\n",
    "2. Predict a few examples with the current weights by calling `nlp.update`\n",
    "3. Compare prediction with true labels\n",
    "4. Calculate how to change weights to improve predictions\n",
    "5. Update weights slightly\n",
    "6. Go back to 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an entity recognizer\n",
    "\n",
    "- The entity recognizer tags words and phrases in context\n",
    "- Each token can only be part of one entity\n",
    "- Examples need to come with context\n",
    "- Texts with no entities are also important (helps w/ generalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example w/ entity 'GADGET'\n",
    "(\"iPhone X is coming\", {'entities': [(0, 8, 'GADGET')]})\n",
    "\n",
    "# example w/o entities\n",
    "(\"I need a new phone! Any tips?\", {'entities': []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training Data\n",
    "\n",
    "Here is an example using spaCyâ€™s rule-based `Matcher` to quickly create training data for named entity models.\n",
    "\n",
    "Using `Matcher` to identify iPhone models:\n",
    "- Write a pattern for two tokens whose lowercase forms match 'iphone' and 'x'.\n",
    "- Write a pattern for two tokens: one token whose lowercase form matches 'iphone' and an optional digit using the '?' operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['How to preorder the iPhone X', 'iPhone X is coming', 'Should I pay $1,000 for the iPhone X?', 'The iPhone 8 reviews are here', 'Your iPhone goes up to 11 today', 'I need a new phone! Any tips?']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "req = requests.get(\"https://raw.githubusercontent.com/ines/spacy-course/master/exercises/iphone.json\")\n",
    "TEXTS = [item for item in req.json()]\n",
    "print(TEXTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Two tokens whose lowercase forms match 'iphone' and 'x'\n",
    "pattern1 = [{\"LOWER\": \"iphone\"}, {\"LOWER\": \"x\"}]\n",
    "\n",
    "# Token whose lowercase form matches 'iphone' and an optional digit\n",
    "pattern2 = [{\"LOWER\": \"iphone\"}, {\"IS_DIGIT\": True, \"OP\": \"?\"}]\n",
    "\n",
    "# Add patterns to the matcher\n",
    "matcher.add(\"GADGET\", None, pattern1, pattern2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches: ['iPhone X', 'iPhone']\n",
      "Matches: ['iPhone X', 'iPhone']\n",
      "Matches: ['iPhone X', 'iPhone']\n",
      "Matches: ['iPhone 8']\n",
      "Matches: ['iPhone']\n",
      "Matches: []\n"
     ]
    }
   ],
   "source": [
    "for doc in nlp.pipe(TEXTS):\n",
    "    matches = matcher(doc)\n",
    "    print(\"Matches:\", [doc[start:end].text for match_id, start, end in matches])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline to bootstrap a set of training examples\n",
    "\n",
    "- Create a doc object for each text using `nlp.pipe`.\n",
    "- Match on the `doc` and create a list of matched spans.\n",
    "- Get `(start character, end character, label)` tuples of matched spans.\n",
    "- Format each example as a tuple of the text and a dict, mapping `'entities'` to the entity tuples.\n",
    "- Append the example to `TRAINING_DATA` and inspect the printed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('How to preorder the iPhone X', {'entities': [(20, 28, 'GADGET')]})\n",
      "('iPhone X is coming', {'entities': [(0, 8, 'GADGET')]})\n",
      "('Should I pay $1,000 for the iPhone X?', {'entities': [(28, 36, 'GADGET')]})\n",
      "('The iPhone 8 reviews are here', {'entities': [(4, 12, 'GADGET')]})\n",
      "('Your iPhone goes up to 11 today', {'entities': []})\n",
      "('I need a new phone! Any tips?', {'entities': []})\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "pattern1 = [{\"LOWER\": \"iphone\"}, {\"LOWER\": \"x\"}]\n",
    "pattern2 = [{\"LOWER\": \"iphone\"}, {\"IS_DIGIT\": True, \"OP\": \"+\"}]\n",
    "\n",
    "matcher.add(\"GADGET\", None, pattern1, pattern2)\n",
    "\n",
    "TRAINING_DATA = []\n",
    "\n",
    "# Create a Doc object for each text in TEXTS\n",
    "for doc in nlp.pipe(TEXTS):\n",
    "    # Match on the doc and create a list of matched spans\n",
    "    spans = [doc[start:end] for match_id, start, end in matcher(doc)]\n",
    "    # Get (start character, end character, label) tuples of matches\n",
    "    entities = [(span.start_char, span.end_char, \"GADGET\") for span in spans]\n",
    "    # Format the matches as a (doc.text, entities) tuple\n",
    "    training_example = (doc.text, {\"entities\": entities})\n",
    "    # Append the example to the training data\n",
    "    TRAINING_DATA.append(training_example)\n",
    "\n",
    "print(*TRAINING_DATA, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
