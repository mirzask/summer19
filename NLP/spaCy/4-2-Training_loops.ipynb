{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop in spaCy\n",
    "\n",
    "1. Loop for a number of times.\n",
    "2. Shuffle the training data - a la SGD; prevents the model from getting stuck in a suboptimal solution\n",
    "3. Divide the data into batches (\"minibatching\") - gives more accurate estimate of the gradient\n",
    "4. Update the model for each batch.\n",
    "5. Save the updated model.\n",
    "\n",
    "Example code using 10 loops:\n",
    "\n",
    "```\n",
    "# Loop for 10 iterations\n",
    "for i in range(10):\n",
    "    # Shuffle the training data\n",
    "    random.shuffle(TRAINING_DATA)\n",
    "    # Create batches and iterate over them\n",
    "    for batch in spacy.util.minibatch(TRAINING_DATA):\n",
    "        # Split the batch in texts and annotations\n",
    "        texts = [text for text, annotation in batch]\n",
    "        annotations = [annotation for text, annotation in batch]\n",
    "        # Update the model\n",
    "        nlp.update(texts, annotations)\n",
    "\n",
    "# Save the model\n",
    "nlp.to_disk(path_to_model)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Setting up a new pipeline from scratch\n",
    "\n",
    "```\n",
    "# Start with blank English model\n",
    "nlp = spacy.blank('en')\n",
    "# Create blank entity recognizer and add it to the pipeline\n",
    "ner = nlp.create_pipe('ner')\n",
    "nlp.add_pipe(ner)\n",
    "# Add a new label\n",
    "ner.add_label('GADGET')\n",
    "\n",
    "# Start the training\n",
    "nlp.begin_training()\n",
    "# Train for 10 iterations\n",
    "for itn in range(10):\n",
    "    random.shuffle(examples)\n",
    "    # Divide examples into batches\n",
    "    for batch in spacy.util.minibatch(examples, size=2):\n",
    "        texts = [text for text, annotation in batch]\n",
    "        annotations = [annotation for text, annotation in batch]\n",
    "        # Update the model\n",
    "        nlp.update(texts, annotations)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['How to preorder the iPhone X', {'entities': [[20, 28, 'GADGET']]}], ['iPhone X is coming', {'entities': [[0, 8, 'GADGET']]}], ['Should I pay $1,000 for the iPhone X?', {'entities': [[28, 36, 'GADGET']]}], ['The iPhone 8 reviews are here', {'entities': [[4, 12, 'GADGET']]}], ['Your iPhone goes up to 11 today', {'entities': [[5, 11, 'GADGET']]}], ['I need a new phone! Any tips?', {'entities': []}]]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "req = requests.get(\"https://raw.githubusercontent.com/ines/spacy-course/master/exercises/gadgets.json\")\n",
    "TRAINING_DATA = [item for item in req.json()]\n",
    "print(TRAINING_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 12.799999833106995}\n",
      "{'ner': 21.858524560928345}\n",
      "{'ner': 31.59492552280426}\n",
      "{'ner': 5.870618999004364}\n",
      "{'ner': 12.188948512077332}\n",
      "{'ner': 17.54018685221672}\n",
      "{'ner': 2.850046828389168}\n",
      "{'ner': 5.846153929363936}\n",
      "{'ner': 7.571244296152145}\n",
      "{'ner': 3.6504366922890767}\n",
      "{'ner': 4.718048918351997}\n",
      "{'ner': 6.092694667197065}\n",
      "{'ner': 3.459057238243986}\n",
      "{'ner': 6.7113398791407235}\n",
      "{'ner': 8.444608137884643}\n",
      "{'ner': 1.0007012260030024}\n",
      "{'ner': 3.914769775874447}\n",
      "{'ner': 5.604732101724949}\n",
      "{'ner': 0.7986384892937366}\n",
      "{'ner': 3.5540181753348605}\n",
      "{'ner': 3.916439884911526}\n",
      "{'ner': 0.12369860630360563}\n",
      "{'ner': 0.23911744905819887}\n",
      "{'ner': 2.3206883766008506}\n",
      "{'ner': 0.001701773064610279}\n",
      "{'ner': 1.4195155765795562}\n",
      "{'ner': 1.4199137895919876}\n",
      "{'ner': 0.0015995474786905106}\n",
      "{'ner': 0.8970869711274645}\n",
      "{'ner': 0.8970974739667594}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import random\n",
    "\n",
    "# Create a blank 'en' model\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Create a new entity recognizer and add it to the pipeline\n",
    "ner = nlp.create_pipe(\"ner\")\n",
    "nlp.add_pipe(ner)\n",
    "\n",
    "# Add the label 'GADGET' to the entity recognizer\n",
    "ner.add_label(\"GADGET\")\n",
    "\n",
    "# Start the training\n",
    "nlp.begin_training()\n",
    "\n",
    "# Loop for 10 iterations\n",
    "for itn in range(10):\n",
    "    # Shuffle the training data\n",
    "    random.shuffle(TRAINING_DATA)\n",
    "    losses = {}\n",
    "\n",
    "    # Batch the examples and iterate over them\n",
    "    for batch in spacy.util.minibatch(TRAINING_DATA, size=2):\n",
    "        texts = [text for text, entities in batch]\n",
    "        annotations = [entities for text, entities in batch]\n",
    "\n",
    "        # Update the model\n",
    "        nlp.update(texts, annotations, losses=losses)\n",
    "        print(losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
